{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append(\"/usr/local/lib/python3.7/site-packages\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from sklearn.impute import SimpleImputer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read responses\n",
    "resp = pd.read_csv('../data/pseudo/responses-pseudo.csv')\n",
    "resp.rename(columns = {'OriginalID':'id', 'LabID': 'strain'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>strain</th>\n",
       "      <th>carb</th>\n",
       "      <th>toby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA151</td>\n",
       "      <td>ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...</td>\n",
       "      <td>210.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IC1</td>\n",
       "      <td>ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A237</td>\n",
       "      <td>ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5920</td>\n",
       "      <td>ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LiA96</td>\n",
       "      <td>ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>JD318</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>360.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Jp238</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Jp1303</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>134.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>JD304</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>351.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>LiA131</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           sequence  strain   carb  \\\n",
       "0     TA151  ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...   210.0   True   \n",
       "1       IC1  ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...    55.0  False   \n",
       "2      A237  ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...    14.0   True   \n",
       "3      5920  ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...     NaN    NaN   \n",
       "4     LiA96  ATGAGTGATCTGCCAAGTCCGAAGAAACACAAGACCTCGAACTGGT...   175.0  False   \n",
       "..      ...                                                ...     ...    ...   \n",
       "117   JD318  ----------------------------------------------...   360.0  False   \n",
       "118   Jp238  ----------------------------------------------...   126.0  False   \n",
       "119  Jp1303  ----------------------------------------------...   134.0  False   \n",
       "120   JD304  ----------------------------------------------...   351.0  False   \n",
       "121  LiA131  ----------------------------------------------...   148.0  False   \n",
       "\n",
       "      toby  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3      NaN  \n",
       "4    False  \n",
       "..     ...  \n",
       "117  False  \n",
       "118  False  \n",
       "119  False  \n",
       "120  False  \n",
       "121  False  \n",
       "\n",
       "[122 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read gene sequences\n",
    "src = SeqIO.parse('../data/pseudo/concatenated.fasta', 'fasta')\n",
    "seq = [(record.id, record.seq._data) for record in src]\n",
    "seq_df = pd.DataFrame(data = seq, columns = ['id', 'sequence'])\n",
    "data = pd.merge(seq_df, resp, on = 'id')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# integer encoding\n",
    "def base2integer(str):\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(['A','T','C','G','-'])\n",
    "    for i in str.split():\n",
    "        return label_encoder.transform(list(i))\n",
    "\n",
    "def integer(series):\n",
    "    label_encoded = series.apply(base2integer)\n",
    "    return pd.DataFrame(label_encoded.to_dict()).transpose()\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "label_encoded = integer(data['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<119x814557 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 57516627 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "def onehot(series):\n",
    "    label_encoded = integer(series).to_numpy()   \n",
    "    onehot_encoder = OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "    onehot_encoded = onehot_encoder.fit_transform(label_encoded)\n",
    "    return onehot_encoded\n",
    "\n",
    "seq_encoded = onehot(data['sequence'])\n",
    "seq_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_imputed = data['sequence'].replace('-', np.NaN)\n",
    "naive = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "naive.fit(seq_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %timeit s = pd.DataFrame.from_dict(data['sequence'].apply(list).to_dict()).transpose()\n",
    "# naive = lambda column: column.where(column!='-', column.value_counts().idxmax())\n",
    "# seq_imputed = s.apply(naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Integer Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = label_encoded\n",
    "y1, y2 = data['carb'].astype('bool'), data['toby'].astype('bool')\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, stratify=y1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, stratify=y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb, penalty=l1\n",
      "Accuracy Score: 0.8333333333333334\n",
      "F1 score: 0.6153846153846153\n",
      "Recall score: 0.6666666666666666\n",
      "Precision score: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "lr_l1 = LogisticRegression(C=1, tol=0.01, penalty='l1', solver='saga', class_weight='balanced')\n",
    "lr_l1.fit(X1_train, y1_train)\n",
    "y1_pred = lr_l1.predict(X1_test)\n",
    "print('carb, penalty=l1')\n",
    "print(f'Accuracy Score: {lr_l1.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby, penalty=l1\n",
      "Accuracy Score: 0.7666666666666667\n",
      "F1 score: 0.22222222222222224\n",
      "Recall score: 0.5\n",
      "Precision score: 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "lr_l1.fit(X2_train, y2_train)\n",
    "y2_pred = lr_l1.predict(X2_test)\n",
    "print('toby, penalty=l1')\n",
    "print(f'Accuracy Score: {lr_l1.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb, penalty=l2\n",
      "Accuracy Score: 0.8333333333333334\n",
      "F1 score: 0.4444444444444444\n",
      "Recall score: 0.3333333333333333\n",
      "Precision score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "lr_l2 = LogisticRegression(C=1, tol=0.01, penalty='l2', solver='lbfgs', class_weight='balanced')\n",
    "lr_l2.fit(X1_train, y1_train)\n",
    "y1_pred = lr_l2.predict(X1_test)\n",
    "print('carb, penalty=l2')\n",
    "print(f'Accuracy Score: {lr_l2.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby, penalty=l2\n",
      "Accuracy Score: 0.9\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n"
     ]
    }
   ],
   "source": [
    "lr_l2.fit(X2_train, y2_train)\n",
    "y2_pred = lr_l2.predict(X2_test)\n",
    "print('toby, penalty=l2')\n",
    "print(f'Accuracy Score: {lr_l2.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb, penalty=elasticnet\n",
      "Accuracy Score: 0.8\n",
      "F1 score: 0.5714285714285715\n",
      "Recall score: 0.6666666666666666\n",
      "Precision score: 0.5\n"
     ]
    }
   ],
   "source": [
    "lr_en = LogisticRegression(C=1, tol=0.01, penalty='elasticnet', solver='saga', l1_ratio=0.5, class_weight='balanced')\n",
    "lr_en.fit(X1_train, y1_train)\n",
    "y1_pred = lr_en.predict(X1_test)\n",
    "print('carb, penalty=elasticnet')\n",
    "print(f'Accuracy Score: {lr_en.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby, penalty=elasticnet\n",
      "Accuracy Score: 0.6333333333333333\n",
      "F1 score: 0.15384615384615385\n",
      "Recall score: 0.5\n",
      "Precision score: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "lr_en.fit(X2_train, y2_train)\n",
    "y2_pred = lr_en.predict(X2_test)\n",
    "print('toby, penalty=elasticnet')\n",
    "print(f'Accuracy Score: {lr_en.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb\n",
      "Accuracy Score: 0.8333333333333334\n",
      "F1 score: 0.6153846153846153\n",
      "Recall score: 0.6666666666666666\n",
      "Precision score: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "svm = svm.SVC(gamma='auto', class_weight='balanced')\n",
    "svm.fit(X1_train, y1_train)\n",
    "y1_pred = svm.predict(X1_test)\n",
    "print('carb')\n",
    "print(f'Accuracy Score: {svm.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby\n",
      "Accuracy Score: 0.8333333333333334\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X2_train, y2_train)\n",
    "y2_pred = svm.predict(X1_test)\n",
    "print('toby')\n",
    "print(f'Accuracy Score: {svm.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb\n",
      "Accuracy Score: 0.8666666666666667\n",
      "F1 score: 0.6\n",
      "Recall score: 0.5\n",
      "Precision score: 0.75\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=5)\n",
    "rf.fit(X1_train, y1_train)\n",
    "y1_pred = rf.predict(X1_test)\n",
    "print('carb')\n",
    "print(f'Accuracy Score: {rf.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby\n",
      "Accuracy Score: 0.9\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X2_train, y2_train)\n",
    "y2_pred = rf.predict(X2_test)\n",
    "print('toby')\n",
    "print(f'Accuracy Score: {rf.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) One-hot Encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = seq_encoded.todense()\n",
    "y1, y2 = data['carb'].astype('bool'), data['toby'].astype('bool')\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, stratify=y1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, stratify=y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb, penalty=l1\n",
      "Accuracy Score: 0.8\n",
      "F1 score: 0.4\n",
      "Recall score: 0.3333333333333333\n",
      "Precision score: 0.5\n",
      "0.6249999999999999\n"
     ]
    }
   ],
   "source": [
    "lr_l1 = LogisticRegression(C=1, tol=0.01, penalty='l1', solver='saga', class_weight='balanced')\n",
    "lr_l1.fit(X1_train, y1_train)\n",
    "y1_pred = lr_l1.predict(X1_test)\n",
    "print('carb, penalty=l1')\n",
    "print(f'Accuracy Score: {lr_l1.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')\n",
    "print(roc_auc_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby, penalty=l1\n",
      "Accuracy Score: 0.7333333333333333\n",
      "F1 score: 0.2\n",
      "Recall score: 0.5\n",
      "Precision score: 0.125\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "lr_l1 = LogisticRegression(C=1, tol=0.01, penalty='l1', solver='saga', class_weight='balanced')\n",
    "lr_l1.fit(X2_train, y2_train)\n",
    "y2_pred = lr_l1.predict(X2_test)\n",
    "print('toby, penalty=l1')\n",
    "print(f'Accuracy Score: {lr_l1.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb, penalty=l2\n",
      "Accuracy Score: 0.7666666666666667\n",
      "F1 score: 0.2222222222222222\n",
      "Recall score: 0.16666666666666666\n",
      "Precision score: 0.3333333333333333\n",
      "0.5416666666666666\n"
     ]
    }
   ],
   "source": [
    "lr_l2 = LogisticRegression(C=1, tol=0.01, penalty='l2', solver='lbfgs', class_weight='balanced')\n",
    "lr_l2.fit(X1_train, y1_train)\n",
    "y1_pred = lr_l2.predict(X1_test)\n",
    "print('carb, penalty=l2')\n",
    "print(f'Accuracy Score: {lr_l2.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')\n",
    "print(roc_auc_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby, penalty=l2\n",
      "Accuracy Score: 0.9\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "0.48214285714285715\n"
     ]
    }
   ],
   "source": [
    "lr_l2.fit(X2_train, y2_train)\n",
    "y2_pred = lr_l2.predict(X2_test)\n",
    "print('toby, penalty=l2')\n",
    "print(f'Accuracy Score: {lr_l2.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')\n",
    "print(roc_auc_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb, penalty=elasticnet\n",
      "Accuracy Score: 0.8\n",
      "F1 score: 0.4\n",
      "Recall score: 0.3333333333333333\n",
      "Precision score: 0.5\n",
      "0.6249999999999999\n"
     ]
    }
   ],
   "source": [
    "lr_en = LogisticRegression(C=1, tol=0.01, penalty='elasticnet', solver='saga', l1_ratio=0.5, class_weight='balanced')\n",
    "lr_en.fit(X1_train, y1_train)\n",
    "y1_pred = lr_en.predict(X1_test)\n",
    "print('carb, penalty=elasticnet')\n",
    "print(f'Accuracy Score: {lr_en.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')\n",
    "print(roc_auc_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby, penalty=elasticnet\n",
      "Accuracy Score: 0.9333333333333333\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_en.fit(X2_train, y2_train)\n",
    "y2_pred = lr_en.predict(X2_test)\n",
    "print('toby, penalty=elasticnet')\n",
    "print(f'Accuracy Score: {lr_en.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')\n",
    "print(roc_auc_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb\n",
      "Accuracy Score: 0.7666666666666667\n",
      "F1 score: 0.3636363636363636\n",
      "Recall score: 0.3333333333333333\n",
      "Precision score: 0.4\n",
      "0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC(gamma='auto', class_weight='balanced')\n",
    "svm.fit(X1_train, y1_train)\n",
    "y1_pred = svm.predict(X1_test)\n",
    "print('carb')\n",
    "print(f'Accuracy Score: {svm.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')\n",
    "print(roc_auc_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby\n",
      "Accuracy Score: 0.7333333333333333\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "0.44642857142857145\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X2_train, y2_train)\n",
    "y2_pred = svm.predict(X1_test)\n",
    "print('toby')\n",
    "print(f'Accuracy Score: {svm.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')\n",
    "print(roc_auc_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carb\n",
      "Accuracy Score: 0.8\n",
      "F1 score: 0.25\n",
      "Recall score: 0.16666666666666666\n",
      "Precision score: 0.5\n",
      "0.5625\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=5)\n",
    "rf.fit(X1_train, y1_train)\n",
    "y1_pred = rf.predict(X1_test)\n",
    "print('carb')\n",
    "print(f'Accuracy Score: {rf.score(X1_test, y1_test)}')\n",
    "print(f'F1 score: {f1_score(y1_test, y1_pred)}')\n",
    "print(f'Recall score: {recall_score(y1_test, y1_pred)}')\n",
    "print(f'Precision score: {precision_score(y1_test, y1_pred)}')\n",
    "print(roc_auc_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toby\n",
      "Accuracy Score: 0.9333333333333333\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Precision score: 0.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=5)\n",
    "rf.fit(X2_train, y2_train)\n",
    "y2_pred = rf.predict(X2_test)\n",
    "print('toby')\n",
    "print(f'Accuracy Score: {rf.score(X2_test, y2_test)}')\n",
    "print(f'F1 score: {f1_score(y2_test, y2_pred)}')\n",
    "print(f'Recall score: {recall_score(y2_test, y2_pred)}')\n",
    "print(f'Precision score: {precision_score(y2_test, y2_pred)}')\n",
    "print(roc_auc_score(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
