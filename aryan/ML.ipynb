{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt \n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "def read_pseudo():\n",
    "    file = SeqIO.parse('concatenated.fasta', 'fasta')\n",
    "    data = [(record.id, record.seq._data) for record in file]\n",
    "    seq = pd.DataFrame(data=data, columns=['id', 'sequence'])\n",
    "    return seq\n",
    "\n",
    "def read_staph():\n",
    "    file = SeqIO.parse('core_gene_alignment-narsa.aln', 'fasta')\n",
    "    data = [(record.id, record.seq._data) for record in file]\n",
    "    seq = pd.DataFrame(data=data, columns=['id', 'sequence'])\n",
    "    return staph\n",
    "\n",
    "def pseudo_resp():\n",
    "    responses= pd.read_csv('responses-pseudo.csv')\n",
    "    return responses\n",
    "\n",
    "def staph_resp():\n",
    "    responses= pd.read_csv('responses-staph.csv')\n",
    "    return responses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo=pseudo_resp()\n",
    "pseudo['carb'] = pseudo['carb'].fillna(0)\n",
    "resp=pseudo['carb']\n",
    "\n",
    "allSeqs = []\n",
    "for seq_record in SeqIO.parse('concatenated.fasta',  'fasta'):\n",
    "      allSeqs.append(seq_record.seq)\n",
    "\n",
    "seqMat = np.array(allSeqs)\n",
    "print(seqMat.shape)\n",
    "seqMat=seqMat[0:122,:]\n",
    "print(seqMat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=np.array(resp, dtype='object')\n",
    "test*= 1\n",
    "#changes all NA values to 0 too\n",
    "new_lst = [[i] for i in test]\n",
    "new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding \n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def hot_ohe(seq_array):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "    onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "    return onehot_encoded_seq\n",
    "\n",
    "def hot_ie(seq_array):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "    onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "    return integer_encoded_seq\n",
    "\n",
    "def ordinal_encoder(my_array):\n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25 # A\n",
    "    float_encoded[float_encoded == 1] = 0.50 # C\n",
    "    float_encoded[float_encoded == 2] = 0.75 # G\n",
    "    float_encoded[float_encoded == 3] = 1.00 # T\n",
    "    float_encoded[float_encoded == 4] = 0.00 # anything else, z\n",
    "    return float_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['A','C','G','T','-']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483333,)\n"
     ]
    }
   ],
   "source": [
    "a=ordinal_encoder(seqMat[0])\n",
    "\n",
    "print(a.shape)\n",
    "i=1\n",
    "while i<122:\n",
    "    b=ordinal_encoder(seqMat[i])\n",
    "    a=np.vstack((a, b))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#practice\n",
    "#a=ordinal_encoder(seqMat[0])\n",
    "#b=ordinal_encoder(seqMat[1])\n",
    "#a=np.vstack((a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nearest neighbor imputation\n",
    "#from sklearn.impute import KNNImputer\n",
    "#nan='-'\n",
    "#imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "#imputer.fit_transform(seqMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.70 TiB for an array with shape (483333, 483333) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-09ea73ed1577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_train2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my_train2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mw_opt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0my_train2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_hat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_eval2\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw_opt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0merror_vec3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 1.70 TiB for an array with shape (483333, 483333) and data type float64"
     ]
    }
   ],
   "source": [
    "#print([key for key in in_data]) \n",
    "# -- use this line to see the keys in the dictionary data structure \n",
    "#linear classifier using feature calculation\n",
    "x = a\n",
    "y = new_lst\n",
    "errorVariable=0\n",
    "i=0\n",
    "\n",
    "while i<122:\n",
    "    x_eval2=x[i:i+12,:]\n",
    "    y_eval2=y[i:i+12]\n",
    "    x_train2=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train2=np.delete(y,np.s_[i:i+12],0)\n",
    "    w_opt2 = np.linalg.inv(x_train2.transpose()@x_train2)@x_train2.transpose()@y_train2\n",
    "    y_hat2 = np.sign(x_eval2@w_opt2)\n",
    "    error_vec3 = [0 if i[0]==i[1] else 1 for i in np.hstack((y_hat2, y_eval2))]\n",
    "    errorVariable = errorVariable+sum(error_vec3)/12\n",
    "    i+=12\n",
    "    \n",
    "print('Total number of errors: ' + str(errorVariable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of SVM model (ordinal_encoding)\n",
      "Prediction accuracy for the first 22 items as testing set: 0.99\n",
      "Prediction accuracy for the second 22 items as testing set: 1.0\n",
      "Prediction after dividing the data into ten segments for Psuedo: 0.7847222222222222\n"
     ]
    }
   ],
   "source": [
    "#Psuedomonas SVM for all datasets\n",
    "print('Calculating accuracy of SVM model (ordinal_encoding)')\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "x = a\n",
    "y = new_lst\n",
    "x_train=x[1:100,:]\n",
    "y_train=y[1:100]\n",
    "x_test=np.delete(x,np.s_[100:122],0)\n",
    "y_test=np.delete(y,np.s_[100:122],0)\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "y_pred = clf.predict(x_test)\n",
    "print('Prediction accuracy for the first 22 items as testing set: '+str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "x_train=x[22:122,:]\n",
    "y_train=y[22:122]\n",
    "x_test=np.delete(x,np.s_[0:22],0)\n",
    "y_test=np.delete(y,np.s_[0:22],0)\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "y_pred = clf.predict(x_test)\n",
    "print('Prediction accuracy for the second 22 items as testing set: '+str(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    totalSum+=accuracy\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into ten segments for Psuedo: ' + str(totalSum/12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy if we take encoding to be the ASCII values for the letters \n",
    "def ordinal_encoder2(my_array):\n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 65 # A\n",
    "    float_encoded[float_encoded == 1] = 67 # C\n",
    "    float_encoded[float_encoded == 2] = 71 # G\n",
    "    float_encoded[float_encoded == 3] = 84 # T\n",
    "    float_encoded[float_encoded == 4] = 0 # anything else, z\n",
    "    return float_encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of SVM model (ordinal_encoding with ASCII values)\n",
      "Prediction after dividing the data into ten segments for Psuedo: 0.8124999999999999\n"
     ]
    }
   ],
   "source": [
    "#aaccuracy if the encoding is changed to ASCII values instead of values that multiples of each other\n",
    "\n",
    "print('Calculating accuracy of SVM model (ordinal_encoding with ASCII values)')\n",
    "\n",
    "a2=ordinal_encoder2(seqMat[0])\n",
    "i=1\n",
    "while i<122:\n",
    "    b2=ordinal_encoder2(seqMat[i])\n",
    "    a2=np.vstack((a2, b2))\n",
    "    i+=1\n",
    "\n",
    "x = a2\n",
    "y = new_lst\n",
    "    \n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    totalSum+=accuracy_score(y_test,y_pred)\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into ten segments for Psuedo: ' + str(totalSum/12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67. 65. 84. ... 65. 65. 65.]\n",
      " [67. 65. 84. ... 65. 84. 67.]\n",
      " [67. 65. 84. ... 65. 84. 67.]\n",
      " ...\n",
      " [65. 65. 65. ... 65. 84. 67.]\n",
      " [65. 65. 65. ... 65. 84. 67.]\n",
      " [65. 65. 65. ... 65. 84. 67.]]\n"
     ]
    }
   ],
   "source": [
    "#nearest neighbor imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "a2[a2 == 0] = 'nan'\n",
    "nan='nan'\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "#stores the imputed array\n",
    "a3=imputer.fit_transform(a2)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of SVM model (ordinal_encoding with imputation to ASCII values)\n",
      "Prediction after dividing the data into twelve segments for Psuedo: 0.7847222222222222\n"
     ]
    }
   ],
   "source": [
    "#accuracy if the encoding is changed to ASCII values instead of values that multiples of each other\n",
    "#and values are imputed based on near neighbor techniques\n",
    "\n",
    "print('Calculating accuracy of SVM model (ordinal_encoding with imputation to ASCII values)')\n",
    "\n",
    "x = a3\n",
    "y = new_lst\n",
    "    \n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    totalSum+=accuracy_score(y_test,y_pred)\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into twelve segments for Psuedo: ' + str(totalSum/12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nearest neighbor imputation using nn=2, for ordinal_encoding\n",
    "a[a == 0] = 'nan'\n",
    "nan='nan'\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "#stores the imputed array\n",
    "a4=imputer.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of SVM model (ordinal_encoding with imputation)\n",
      "Prediction after dividing the data into twelve segments for Psuedo: 0.7569444444444445\n"
     ]
    }
   ],
   "source": [
    "print('Calculating accuracy of SVM model (ordinal_encoding with imputation)')\n",
    "\n",
    "x = a4\n",
    "y = new_lst\n",
    "    \n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    totalSum+=accuracy_score(y_test,y_pred)\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into twelve segments for Psuedo: ' + str(totalSum/12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of SVM model (ordinal_encoding with KNN (n=5) imputation to ASCII values)\n",
      "Prediction after dividing the data into twelve segments for Psuedo: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "#accuracy if the encoding is changed to ASCII values instead of values that multiples of each other\n",
    "#and values are imputed based on near neighbor techniques, where nn = 5\n",
    "\n",
    "print('Calculating accuracy of SVM model (ordinal_encoding with KNN (n=5) imputation to ASCII values)')\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "x = imputer.fit_transform(a2)\n",
    "y = new_lst\n",
    "    \n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    totalSum+=accuracy_score(y_test,y_pred)\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into twelve segments for Psuedo: ' + str(totalSum/12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for toby\n",
    "resp2=pseudo['toby'].fillna(0)\n",
    "toby=np.array(resp2, dtype='object')\n",
    "toby*= 1\n",
    "#changes all NA values to 0 too\n",
    "new_lst2 = [[j] for j in toby]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting SVM accuracy when considering Toby responses, for ordinal encoding with ASCII values[including imputation]\n",
      "Prediction after dividing the data into ten segments for Psuedo: 0.9097222222222223\n",
      "Predicting SVM accuracy when considering Toby responses, for ordinal encoding including imputation]\n",
      "Prediction after dividing the data into ten segments for Psuedo: 0.9236111111111112\n"
     ]
    }
   ],
   "source": [
    "#SVM testing for Toby responses with ordinal encoding with ASCII values \n",
    "\n",
    "print('Predicting SVM accuracy when considering Toby responses, for ordinal encoding with ASCII values[including imputation]')\n",
    "x = a3\n",
    "y = new_lst2\n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    totalSum+=accuracy\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into ten segments for Psuedo: ' + str(totalSum/12))\n",
    "\n",
    "print('Predicting SVM accuracy when considering Toby responses, for ordinal encoding including imputation')\n",
    "\n",
    "x = a4\n",
    "y = new_lst2\n",
    "\n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "    totalSum+=accuracy\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into ten segments for Psuedo: ' + str(totalSum/12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy of SVM model (ordinal_encoding with KNN (n=5) imputation to ASCII values) for responses to Toby\n",
      "Prediction after dividing the data into twelve segments for Psuedo: 0.9097222222222223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Calculating accuracy of SVM model (ordinal_encoding with KNN (n=5) imputation to ASCII values) for responses to Toby')\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "x = imputer.fit_transform(a2)\n",
    "y = new_lst2\n",
    "    \n",
    "i=0\n",
    "totalSum=0\n",
    "while i<120:\n",
    "    x_test=x[i:i+12,:]\n",
    "    y_test=y[i:i+12]\n",
    "    x_train=np.delete(x,np.s_[i:i+12],0)\n",
    "    y_train=np.delete(y,np.s_[i:i+12],0)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(x_train,np.ravel(y_train,order='C'))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    totalSum+=accuracy_score(y_test,y_pred)\n",
    "    i+=10\n",
    "    \n",
    "print('Prediction after dividing the data into twelve segments for Psuedo: ' + str(totalSum/12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 983088)\n",
      "(125, 983088)\n"
     ]
    }
   ],
   "source": [
    "#Begin calculation for Staphylococcus\n",
    "allSeqs = []\n",
    "for seq_record in SeqIO.parse('core_gene_alignment-narsa.aln','fasta'):\n",
    "      allSeqs.append(seq_record.seq)\n",
    "\n",
    "seqMat = np.array(allSeqs)\n",
    "print(seqMat.shape)\n",
    "seqMat=seqMat[0:125,:]\n",
    "print(seqMat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staph=staph_resp()\n",
    "respo=staph['resp'].fillna(0)\n",
    "respo=np.array(respo, dtype='object')\n",
    "respo*= 1\n",
    "#changes all NA values to 0 too\n",
    "new_lst3 = [[j] for j in respo]\n",
    "new_lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=ordinal_encoder(seqMat[0])\n",
    "\n",
    "#print(a.shape)\n",
    "#i=1\n",
    "#while i<122:\n",
    "#    b=ordinal_encoder(seqMat[i])\n",
    "#    a=np.vstack((a, b))\n",
    "#    i+=1\n",
    "    \n",
    "#a[a == 0] = 'nan'\n",
    "#nan='nan'\n",
    "#imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "#stores the imputed array\n",
    "#a2=imputer.fit_transform(a)\n",
    "#a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aryan'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
