{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from load import load_staph, load_condons\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_colwidth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 248 ms, total: 10.8 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>sequence_i</th>\n",
       "      <th>missing_i</th>\n",
       "      <th>missing_%_i</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2511</td>\n",
       "      <td>0.255</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2356</td>\n",
       "      <td>0.240</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NRS002</td>\n",
       "      <td>------...</td>\n",
       "      <td>25278</td>\n",
       "      <td>2.571</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2236</td>\n",
       "      <td>0.227</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NRS003</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>48213</td>\n",
       "      <td>4.904</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2253</td>\n",
       "      <td>0.229</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>ATGAAA...</td>\n",
       "      <td>2442</td>\n",
       "      <td>0.248</td>\n",
       "      <td>ATGAAA...</td>\n",
       "      <td>2088</td>\n",
       "      <td>0.212</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>3885</td>\n",
       "      <td>0.395</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.219</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   sequence  missing  missing_% sequence_i  missing_i  missing_%_i  \\\n",
       "0  NRS001  ATGAAC...     2511      0.255  ATGAAC...       2356      0.240     \n",
       "1  NRS002  ------...    25278      2.571  ATGAAC...       2236      0.227     \n",
       "2  NRS003  ATGAAC...    48213      4.904  ATGAAC...       2253      0.229     \n",
       "3  NRS021  ATGAAA...     2442      0.248  ATGAAA...       2088      0.212     \n",
       "4  NRS022  ATGAAC...     3885      0.395  ATGAAC...       2154      0.219     \n",
       "\n",
       "    resp  \n",
       "0  False  \n",
       "1  False  \n",
       "2  False  \n",
       "3  False  \n",
       "4  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time records = load_staph(False)\n",
    "mask = records['resp'].notna()\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 2.55 s, total: 1min 12s\n",
      "Wall time: 1min 15s\n",
      "CPU times: user 1min 14s, sys: 4.67 s, total: 1min 19s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "# 1*2 minutes\n",
    "%time o_c = load_condons('../data/staph/core_gene_alignment-narsa.fasta')\n",
    "%time i_c = load_condons('../data/staph/core_gene_alignment-narsa_naive_impute.fasta')\n",
    "\n",
    "# 1.5 minutes\n",
    "d = {}\n",
    "for label, content in o_c.iteritems():\n",
    "    d.update(content.value_counts().to_dict())\n",
    "d_sorted = dict(sorted(d.items(), key=lambda x: x[1], reverse=True))\n",
    "mapping = {key: i for i, key in enumerate(d_sorted.keys())}\n",
    "\n",
    "import json\n",
    "with open('../data/staph/preprocess/others/condon_mapping.json', 'w') as output:\n",
    "    json.dump(mapping, output, indent='\\t')\n",
    "\n",
    "import json\n",
    "with open('../data/staph/preprocess/others/condon_mapping.json', 'r') as input_:\n",
    "    mapping = json.load(input_)\n",
    "\n",
    "# 1*2 minutes\n",
    "%time o_c_ = o_c.applymap(lambda x: mapping[x])\n",
    "%time i_c_ = i_c.applymap(lambda x: mapping[x])\n",
    "np.save('../data/staph/preprocess/o_c_-_-.npy', o_c_.to_numpy()[mask])\n",
    "np.save('../data/staph/preprocess/i_c_-_-.npy', i_c_.to_numpy()[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c_ = np.load('../data/staph/preprocess/o_c_-_-.npy')\n",
    "i_c_ = np.load('../data/staph/preprocess/i_c_-_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove based on SNP counts\n",
    "similar to variance threshold but seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4*2 minutes\n",
    "%time variant_counts_o = o_c.apply(pd.Series.value_counts, axis=0)\n",
    "%time variant_counts_i = i_c.apply(pd.Series.value_counts, axis=0)\n",
    "np.save('../data/staph/preprocess/others/variant_counts_o.npy', variant_counts_o)\n",
    "np.save('../data/staph/preprocess/others/variant_counts_i.npy', variant_counts_i)\n",
    "\n",
    "variant_counts_o = pd.DataFrame(np.load('../data/staph/preprocess/others/variant_counts_o.npy'))\n",
    "variant_counts_i = pd.DataFrame(np.load('../data/staph/preprocess/others/variant_counts_i.npy'))\n",
    "\n",
    "# True     96576\n",
    "variant_max_counts_o = variant_counts_o.max()\n",
    "# True      40054\n",
    "variant_max_counts_i = variant_counts_i.max()\n",
    "\n",
    "o_c_v = o_c_[mask][:, variant_max_counts_o<124]\n",
    "i_c_v = i_c_[mask][:, variant_max_counts_i<124]\n",
    "np.save('../data/staph/preprocess/o_c_v_-.npy', o_c_v)\n",
    "np.save('../data/staph/preprocess/i_c_v_-.npy', i_c_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^2$ on the previous result\n",
    "because some features are all 0's, so gives `divide by 0` warning\n",
    "\n",
    "no warning if we remove those features (on the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ws/home/zzhang3/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:167: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  chisq /= f_exp\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "o_c_x = SelectKBest(chi2, k=96576//2).fit_transform(o_c_v, records['resp'][mask].astype('i4'))\n",
    "i_c_x = SelectKBest(chi2, k=40054//2).fit_transform(i_c_v, records['resp'][mask].astype('i4'))\n",
    "\n",
    "np.save('../data/staph/preprocess/o_c_x_-.npy', o_c_x)\n",
    "np.save('../data/staph/preprocess/i_c_x_-.npy', i_c_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c_v = np.load('../data/staph/preprocess/o_c_v_-.npy')\n",
    "i_c_v = np.load('../data/staph/preprocess/i_c_v_-.npy')\n",
    "o_c_x = np.load('../data/staph/preprocess/o_c_x_-.npy')\n",
    "i_c_x = np.load('../data/staph/preprocess/i_c_x_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes very long but about one night\n",
    "from strkernel.mismatch_kernel import MismatchKernel\n",
    "\n",
    "%time o_c__s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_)\n",
    "%time i_c__s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_)\n",
    "np.save('../data/staph/preprocess/o_c_-_s.npy', o_c__s.kernel)\n",
    "np.save('../data/staph/preprocess/i_c_-_s.npy', i_c__s.kernel)\n",
    "\n",
    "%time o_c_v_s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_v)\n",
    "%time i_c_v_s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_v)\n",
    "np.save('../data/staph/preprocess/o_c_v_s.npy', o_c_v_s.kernel)\n",
    "np.save('../data/staph/preprocess/i_c_v_s.npy', i_c_v_s.kernel)\n",
    "\n",
    "%time o_c_x_s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_x)\n",
    "%time i_c_x_s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_x)\n",
    "np.save('../data/staph/preprocess/o_c_x_s.npy', o_c_x_s.kernel)\n",
    "np.save('../data/staph/preprocess/i_c_x_s.npy', i_c_x_s.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 24s, sys: 19.1 s, total: 4min 43s\n",
      "Wall time: 11.3 s\n",
      "CPU times: user 3min 59s, sys: 21.9 s, total: 4min 21s\n",
      "Wall time: 11.7 s\n",
      "CPU times: user 55.4 s, sys: 7.39 s, total: 1min 2s\n",
      "Wall time: 3.09 s\n",
      "CPU times: user 32.7 s, sys: 4.58 s, total: 37.3 s\n",
      "Wall time: 1.66 s\n",
      "CPU times: user 35 s, sys: 5.21 s, total: 40.2 s\n",
      "Wall time: 1.85 s\n",
      "CPU times: user 21.7 s, sys: 2.88 s, total: 24.6 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%time o_c__p = PCA(n_components=124).fit_transform(o_c_)\n",
    "%time i_c__p = PCA(n_components=124).fit_transform(i_c_)\n",
    "np.save('../data/staph/preprocess/o_c_-_p.npy', o_c__p)\n",
    "np.save('../data/staph/preprocess/i_c_-_p.npy', i_c__p)\n",
    "\n",
    "%time o_c_v_p = PCA(n_components=124).fit_transform(o_c_v)\n",
    "%time i_c_v_p = PCA(n_components=124).fit_transform(i_c_v)\n",
    "np.save('../data/staph/preprocess/o_c_v_p.npy', o_c_v_p)\n",
    "np.save('../data/staph/preprocess/i_c_v_p.npy', i_c_v_p)\n",
    "\n",
    "%time o_c_x_p = PCA(n_components=124).fit_transform(o_c_x)\n",
    "%time i_c_x_p = PCA(n_components=124).fit_transform(i_c_x)\n",
    "np.save('../data/staph/preprocess/o_c_x_p.npy', o_c_x_p)\n",
    "np.save('../data/staph/preprocess/i_c_x_p.npy', i_c_x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.3 s, sys: 2.5 s, total: 47.8 s\n",
      "Wall time: 4.03 s\n",
      "CPU times: user 47.4 s, sys: 2.43 s, total: 49.8 s\n",
      "Wall time: 4.38 s\n",
      "CPU times: user 43 s, sys: 2.61 s, total: 45.6 s\n",
      "Wall time: 4.42 s\n",
      "CPU times: user 19.1 s, sys: 1.04 s, total: 20.1 s\n",
      "Wall time: 3.02 s\n",
      "CPU times: user 27.3 s, sys: 1.33 s, total: 28.7 s\n",
      "Wall time: 3.98 s\n",
      "CPU times: user 9.44 s, sys: 2.28 s, total: 11.7 s\n",
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%time o_c__t = TSNE(n_components=3).fit_transform(o_c_)\n",
    "%time i_c__t = TSNE(n_components=3).fit_transform(i_c_)\n",
    "np.save('../data/staph/preprocess/o_c_-_t.npy', o_c__t)\n",
    "np.save('../data/staph/preprocess/i_c_-_t.npy', i_c__t)\n",
    "\n",
    "%time o_c_v_t = TSNE(n_components=3).fit_transform(o_c_v)\n",
    "%time i_c_v_t = TSNE(n_components=3).fit_transform(i_c_v)\n",
    "np.save('../data/staph/preprocess/o_c_v_t.npy', o_c_v_t)\n",
    "np.save('../data/staph/preprocess/i_c_v_t.npy', i_c_v_t)\n",
    "\n",
    "%time o_c_x_t = TSNE(n_components=3).fit_transform(o_c_x)\n",
    "%time i_c_x_t = TSNE(n_components=3).fit_transform(i_c_x)\n",
    "np.save('../data/staph/preprocess/o_c_x_t.npy', o_c_x_t)\n",
    "np.save('../data/staph/preprocess/i_c_x_t.npy', i_c_x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify all possible combinations are created\n",
    "import os\n",
    "d = os.listdir('../data/staph/preprocess/')\n",
    "s = {'{}_{}_{}_{}.npy'.format(impute, c_or_n, selection, extraction) for impute in 'io' for c_or_n in 'nc' for selection in '-vx' for extraction in '-pts'}\n",
    "len(s - set(d)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "s = {'{}_c_{}_{}.npy'.format(impute, selection, extraction)\n",
    "     for impute in 'io'\n",
    "     for selection in '-vx'\n",
    "     for extraction in '-pts'}\n",
    "\n",
    "data = {d: np.load(os.path.join('../data/staph/preprocess', d)) for d in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "for file, X in data.items():\n",
    "    encoder = OneHotEncoder(categories='auto', sparse=False, dtype=np.int32)\n",
    "    X_encode = encoder.fit_transform(X)\n",
    "    np.save(os.path.join('../data/staph/preprocess/onehot', file), X_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
