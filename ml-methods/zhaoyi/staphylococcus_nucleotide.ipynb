{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from load import load_staph, load_nucleotides\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_colwidth = 10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 219 ms, total: 10.9 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>sequence_i</th>\n",
       "      <th>missing_i</th>\n",
       "      <th>missing_%_i</th>\n",
       "      <th>resp</th>\n",
       "      <th>Total.Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NRS001</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2511</td>\n",
       "      <td>0.255</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2356</td>\n",
       "      <td>0.240</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NRS002</td>\n",
       "      <td>------...</td>\n",
       "      <td>25278</td>\n",
       "      <td>2.571</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2236</td>\n",
       "      <td>0.227</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NRS003</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>48213</td>\n",
       "      <td>4.904</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2253</td>\n",
       "      <td>0.229</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NRS021</td>\n",
       "      <td>ATGAAA...</td>\n",
       "      <td>2442</td>\n",
       "      <td>0.248</td>\n",
       "      <td>ATGAAA...</td>\n",
       "      <td>2088</td>\n",
       "      <td>0.212</td>\n",
       "      <td>False</td>\n",
       "      <td>473.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NRS022</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>3885</td>\n",
       "      <td>0.395</td>\n",
       "      <td>ATGAAC...</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.219</td>\n",
       "      <td>False</td>\n",
       "      <td>6686.806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   sequence  missing  missing_% sequence_i  missing_i  missing_%_i  \\\n",
       "0  NRS001  ATGAAC...     2511      0.255  ATGAAC...       2356      0.240     \n",
       "1  NRS002  ------...    25278      2.571  ATGAAC...       2236      0.227     \n",
       "2  NRS003  ATGAAC...    48213      4.904  ATGAAC...       2253      0.229     \n",
       "3  NRS021  ATGAAA...     2442      0.248  ATGAAA...       2088      0.212     \n",
       "4  NRS022  ATGAAC...     3885      0.395  ATGAAC...       2154      0.219     \n",
       "\n",
       "    resp  Total.Area  \n",
       "0  False      0.000   \n",
       "1  False      0.000   \n",
       "2  False      0.000   \n",
       "3  False    473.152   \n",
       "4  False   6686.806   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time records = load_staph()\n",
    "mask = records['resp'].notna()\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import Bio\n",
    "with open(\"../data/staph/core_gene_alignment-narsa.fasta\", \"w\") as output:\n",
    "    for sequence in SeqIO.parse('../data/staph/core_gene_alignment-narsa.aln', 'fasta'):\n",
    "        seq = Bio.Seq.Seq(sequence.seq._data.upper(), alphabet=Bio.Alphabet.Alphabet())\n",
    "        record = Bio.SeqRecord.SeqRecord(seq, id=sequence.id, description='')\n",
    "        SeqIO.write(record, output, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 1.5 s, total: 1min 32s\n",
      "Wall time: 1min 28s\n",
      "CPU times: user 1min 28s, sys: 1.19 s, total: 1min 29s\n",
      "Wall time: 1min 24s\n",
      "CPU times: user 1min 33s, sys: 2.07 s, total: 1min 35s\n",
      "Wall time: 1min 31s\n",
      "CPU times: user 1min 34s, sys: 1.91 s, total: 1min 36s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "# 1.5*2 minutes\n",
    "%time o_n = load_nucleotides('../data/staph/core_gene_alignment-narsa.fasta')\n",
    "%time i_n = load_nucleotides('../data/staph/core_gene_alignment-narsa_naive_impute.fasta')\n",
    "\n",
    "# 1.5*2 minutes\n",
    "forward = str.maketrans('-ACTGN', '012345')\n",
    "def transformation(str):\n",
    "    return [int(i) for i in str.translate(forward)]\n",
    "%time o_n = pd.DataFrame(records['sequence'].apply(transformation).to_list())\n",
    "%time i_n = pd.DataFrame(records['sequence_i'].apply(transformation).to_list())\n",
    "np.save('../data/staph/preprocess/o_n_-_-.npy', o_n[mask])\n",
    "np.save('../data/staph/preprocess/i_n_-_-.npy', i_n[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_n = np.load('../data/staph/preprocess/o_n_-_-.npy')\n",
    "i_n = np.load('../data/staph/preprocess/i_n_-_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove based on SNP counts\n",
    "similar to variance threshold but seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11*2 minutes\n",
    "%time snp_counts_o = o_n.apply(pd.Series.value_counts, axis=0)\n",
    "%time snp_counts_i = i_n.apply(pd.Series.value_counts, axis=0)\n",
    "np.save('../data/staph/preprocess/others/snp_counts_o.npy', snp_counts_o.to_numpy())\n",
    "np.save('../data/staph/preprocess/others/snp_counts_i.npy', snp_counts_i.to_numpy())\n",
    "\n",
    "snp_counts_o = pd.DataFrame(np.load('../data/staph/preprocess/others/snp_counts_o.npy'))\n",
    "snp_counts_i = pd.DataFrame(np.load('../data/staph/preprocess/others/snp_counts_i.npy'))\n",
    "\n",
    "# True     218693\n",
    "snp_max_counts_o = snp_counts_o.max()\n",
    "# True     42467\n",
    "snp_max_counts_i = snp_counts_i.max()\n",
    "\n",
    "o_n_v = o_n[mask].loc[:, (snp_max_counts_o<124)]\n",
    "i_n_v = i_n[mask].loc[:, (snp_max_counts_i<124)]\n",
    "np.save('../data/staph/preprocess/o_n_v_-.npy', o_n_v)\n",
    "np.save('../data/staph/preprocess/i_n_v_-.npy', i_n_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^2$ on the previous result\n",
    "because some features are all 0's, so gives `divide by 0` warning\n",
    "\n",
    "no warning if we remove those features (on the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "o_n_x = SelectKBest(chi2, k=218693//2).fit_transform(o_n_v, records['resp'][mask].astype('i4'))\n",
    "i_n_x = SelectKBest(chi2, k=42467//2).fit_transform(i_n_v, records['resp'][mask].astype('i4'))\n",
    "np.save('../data/staph/preprocess/o_n_x_-.npy', o_n_x)\n",
    "np.save('../data/staph/preprocess/i_n_x_-.npy', i_n_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_n_v = np.load('../data/staph/preprocess/o_n_v_-.npy')\n",
    "i_n_v = np.load('../data/staph/preprocess/i_n_v_-.npy')\n",
    "o_n_x = np.load('../data/staph/preprocess/o_n_x_-.npy')\n",
    "i_n_x = np.load('../data/staph/preprocess/i_n_x_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 28min 52s, sys: 24min 9s, total: 6h 53min 2s\n",
      "Wall time: 17min 41s\n",
      "CPU times: user 6h 56min 3s, sys: 47min 50s, total: 7h 43min 53s\n",
      "Wall time: 27min 1s\n",
      "CPU times: user 10min 30s, sys: 1min 23s, total: 11min 54s\n",
      "Wall time: 4min 19s\n",
      "CPU times: user 36.7 s, sys: 2.15 s, total: 38.8 s\n",
      "Wall time: 38.9 s\n",
      "CPU times: user 1min 38s, sys: 7.05 s, total: 1min 46s\n",
      "Wall time: 1min 46s\n",
      "CPU times: user 20 s, sys: 1.08 s, total: 21 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "from strkernel.mismatch_kernel import MismatchKernel\n",
    "\n",
    "# 17~27*2 minutes\n",
    "%time o_n__s = MismatchKernel(l=6, k=3, m=1).get_kernel(o_n)\n",
    "%time i_n__s = MismatchKernel(l=6, k=3, m=1).get_kernel(i_n)\n",
    "np.save('../data/staph/preprocess/o_n_-_s.npy', o_n__s.kernel)\n",
    "np.save('../data/staph/preprocess/i_n_-_s.npy', i_n__s.kernel)\n",
    "\n",
    "# 3+1 minutes\n",
    "%time o_n_v_s = MismatchKernel(l=6, k=3, m=1).get_kernel(o_n_v)\n",
    "%time i_n_v_s = MismatchKernel(l=6, k=3, m=1).get_kernel(i_n_v)\n",
    "np.save('../data/staph/preprocess/o_n_v_s.npy', o_n_v_s.kernel)\n",
    "np.save('../data/staph/preprocess/i_n_v_s.npy', i_n_v_s.kernel)\n",
    "\n",
    "# 2*1 minutes\n",
    "%time o_n_x_s = MismatchKernel(l=6, k=3, m=1).get_kernel(o_n_x)\n",
    "%time i_n_x_s = MismatchKernel(l=6, k=3, m=1).get_kernel(i_n_x)\n",
    "np.save('../data/staph/preprocess/o_n_x_s.npy', o_n_x_s.kernel)\n",
    "np.save('../data/staph/preprocess/i_n_x_s.npy', i_n_x_s.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 40s, sys: 36.8 s, total: 12min 17s\n",
      "Wall time: 27.1 s\n",
      "CPU times: user 11min 45s, sys: 35.3 s, total: 12min 21s\n",
      "Wall time: 26.4 s\n",
      "CPU times: user 3min 8s, sys: 9.61 s, total: 3min 17s\n",
      "Wall time: 6.91 s\n",
      "CPU times: user 27.3 s, sys: 1.82 s, total: 29.2 s\n",
      "Wall time: 904 ms\n",
      "CPU times: user 1min 34s, sys: 6.01 s, total: 1min 40s\n",
      "Wall time: 3.34 s\n",
      "CPU times: user 16.7 s, sys: 1.54 s, total: 18.3 s\n",
      "Wall time: 583 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%time o_n__p = PCA(n_components=124).fit_transform(o_n)\n",
    "%time i_n__p = PCA(n_components=124).fit_transform(i_n)\n",
    "np.save('../data/staph/preprocess/o_n_-_p.npy', o_n__p)\n",
    "np.save('../data/staph/preprocess/i_n_-_p.npy', i_n__p)\n",
    "\n",
    "%time o_n_v_p = PCA(n_components=124).fit_transform(o_n_v)\n",
    "%time i_n_v_p = PCA(n_components=124).fit_transform(i_n_v)\n",
    "np.save('../data/staph/preprocess/o_n_v_p.npy', o_n_v_p)\n",
    "np.save('../data/staph/preprocess/i_n_v_p.npy', i_n_v_p)\n",
    "\n",
    "%time o_n_x_p = PCA(n_components=124).fit_transform(o_n_x)\n",
    "%time i_n_x_p = PCA(n_components=124).fit_transform(i_n_x)\n",
    "np.save('../data/staph/preprocess/o_n_x_p.npy', o_n_x_p)\n",
    "np.save('../data/staph/preprocess/i_n_x_p.npy', i_n_x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 20s, sys: 17 s, total: 5min 37s\n",
      "Wall time: 14.8 s\n",
      "CPU times: user 5min 20s, sys: 17.6 s, total: 5min 38s\n",
      "Wall time: 14.5 s\n",
      "CPU times: user 1min 16s, sys: 4.14 s, total: 1min 20s\n",
      "Wall time: 5.02 s\n",
      "CPU times: user 17.8 s, sys: 962 ms, total: 18.8 s\n",
      "Wall time: 2.73 s\n",
      "CPU times: user 38.9 s, sys: 2.37 s, total: 41.3 s\n",
      "Wall time: 3.66 s\n",
      "CPU times: user 10.8 s, sys: 349 ms, total: 11.1 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%time o_n__t = TSNE(n_components=3).fit_transform(o_n)\n",
    "%time i_n__t = TSNE(n_components=3).fit_transform(i_n)\n",
    "np.save('../data/staph/preprocess/o_n_-_t.npy', o_n__t)\n",
    "np.save('../data/staph/preprocess/i_n_-_t.npy', i_n__t)\n",
    "\n",
    "%time o_n_v_t = TSNE(n_components=3).fit_transform(o_n_v)\n",
    "%time i_n_v_t = TSNE(n_components=3).fit_transform(i_n_v)\n",
    "np.save('../data/staph/preprocess/o_n_v_t.npy', o_n_v_t)\n",
    "np.save('../data/staph/preprocess/i_n_v_t.npy', i_n_v_t)\n",
    "\n",
    "%time o_n_x_t = TSNE(n_components=3).fit_transform(o_n_x)\n",
    "%time i_n_x_t = TSNE(n_components=3).fit_transform(i_n_x)\n",
    "np.save('../data/staph/preprocess/o_n_x_t.npy', o_n_x_t)\n",
    "np.save('../data/staph/preprocess/i_n_x_t.npy', i_n_x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "s = {'{}_n_{}_{}.npy'.format(impute, selection, extraction)\n",
    "     for impute in 'io'\n",
    "     for selection in '-vx'\n",
    "     for extraction in '-pts'}\n",
    "\n",
    "data_u = {d: np.load(os.path.join('../data/staph/preprocess', d)) for d in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "for file, X in data_u.items():\n",
    "    encoder = OneHotEncoder(categories='auto', sparse=False, dtype=np.int32)\n",
    "    X_encode = encoder.fit_transform(X)\n",
    "    np.save(os.path.join('../data/staph/preprocess/onehot', file), X_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_e = {d: np.load(os.path.join('../data/staph/preprocess/onehot', d)) for d in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = records['carb'][mask].astype('?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['i_n_x_p.npy']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y, train_size=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'class_weight': [None, 'balanced', {0:1, 1:4}, {0:1, 1:8}, {0:1, 1:32}, {0:1, 1:64}, {0:1, 1:128}],\n",
    "              'l1_ratio': [0., 0.2, 0.4, 0.6, 0.8, 1.]}\n",
    "clf = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga', max_iter=2000, verbose=1, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 8., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 8., 1., 1., 8., 1., 8., 1., 1., 8., 1., 8., 1.,\n",
       "       1., 1., 1., 8., 1., 1., 8., 8., 1., 1., 1., 1., 8., 1.])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.ones(y_test.shape)\n",
    "weights[y_test] = clf.best_estimator_.class_weight[1]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050847457627118"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(X_test, y_test, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 23],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, clf.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_u_logistic = {}\n",
    "for d, X in data_u.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y, train_size=0.7)\n",
    "    clf = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga', max_iter=2000, verbose=False, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_u_logistic[d] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e_logistic = {}\n",
    "for d, X in data_e.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y, train_size=0.7)\n",
    "    clf = GridSearchCV(LogisticRegression(penalty='elasticnet', solver='saga', max_iter=2000, verbose=False, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))\n",
    "    clf.fit(X_train, y_train)\n",
    "    model_e_logistic[d] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [10, 100, 1000],\n",
    "              'min_samples_split': [2, 3],\n",
    "              'min_samples_leaf': [2, 3],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "              'class_weight': [None, 'balanced', {0:1, 1:4}, {0:1, 1:8}, {0:1, 1:32}, {0:1, 1:64}, {0:1, 1:128}]}\n",
    "clf = GridSearchCV(RandomForestClassifier(verbose=0, n_jobs=5),\n",
    "                   param_grid=param_grid,\n",
    "                   scoring=['recall', 'balanced_accuracy'],\n",
    "                   refit='balanced_accuracy',\n",
    "                   cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 25s, sys: 22.1 s, total: 6min 47s\n",
      "Wall time: 10min 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ws/home/zzhang3/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fractio...\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'class_weight': [None, 'balanced', {0: 1, 1: 4},\n",
       "                                          {0: 1, 1: 8}, {0: 1, 1: 32},\n",
       "                                          {0: 1, 1: 64}, {0: 1, 1: 128}],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', None],\n",
       "                         'min_samples_leaf': [2, 3],\n",
       "                         'min_samples_split': [2, 3],\n",
       "                         'n_estimators': [10, 100, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit='balanced_accuracy',\n",
       "             return_train_score=False, scoring=['recall', 'balanced_accuracy'],\n",
       "             verbose=0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=5,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-1c60142e03f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "weights = np.ones(y_test.shape)\n",
    "weights[y_test] = clf.best_estimator_.class_weight[1]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333333333334"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(X_test, y_test,\n",
    "#                           sample_weight=weights\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37,  1],\n",
       "       [10,  0]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, clf.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
