{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from load import load_pseudo, load_condons\n",
    "\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.max_colwidth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 s, sys: 98.7 ms, total: 5.47 s\n",
      "Wall time: 5.49 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>missing</th>\n",
       "      <th>missing_%</th>\n",
       "      <th>sequence_i</th>\n",
       "      <th>missing_i</th>\n",
       "      <th>missing_%_i</th>\n",
       "      <th>carb</th>\n",
       "      <th>toby</th>\n",
       "      <th>carb_num</th>\n",
       "      <th>toby_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TA151</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>31842</td>\n",
       "      <td>6.588</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>28410</td>\n",
       "      <td>5.878</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>IC1</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>46071</td>\n",
       "      <td>9.532</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>34714</td>\n",
       "      <td>7.182</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A237</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>44514</td>\n",
       "      <td>9.210</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>35933</td>\n",
       "      <td>7.434</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5920</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>49497</td>\n",
       "      <td>10.241</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>36873</td>\n",
       "      <td>7.629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LiA96</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>44067</td>\n",
       "      <td>9.117</td>\n",
       "      <td>ATGAGT...</td>\n",
       "      <td>34454</td>\n",
       "      <td>7.128</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   sequence  missing  missing_% sequence_i  missing_i  missing_%_i  \\\n",
       "0  TA151  ATGAGT...    31842      6.588  ATGAGT...      28410      5.878     \n",
       "1    IC1  ATGAGT...    46071      9.532  ATGAGT...      34714      7.182     \n",
       "2   A237  ATGAGT...    44514      9.210  ATGAGT...      35933      7.434     \n",
       "3   5920  ATGAGT...    49497     10.241  ATGAGT...      36873      7.629     \n",
       "4  LiA96  ATGAGT...    44067      9.117  ATGAGT...      34454      7.128     \n",
       "\n",
       "    carb   toby  carb_num  toby_num  \n",
       "0   True  False      -2.0      16.0  \n",
       "1  False  False       2.0      14.0  \n",
       "2   True  False      -1.0       4.0  \n",
       "3    NaN    NaN       NaN       NaN  \n",
       "4  False  False       0.0      18.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time records = load_pseudo()\n",
    "mask = (records['toby'].notna() & records['carb'].notna())\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25*2 seconds\n",
    "%time o_c = load_condons('../data/pseudo/concatenated.fasta')\n",
    "%time i_c = load_condons('../data/pseudo/concatenated_naive_impute.fasta')\n",
    "\n",
    "# 1.5*2 minutes\n",
    "d = {}\n",
    "for label, content in o_c.iteritems():\n",
    "    d.update(content.value_counts().to_dict())\n",
    "d_sorted = dict(sorted(d.items(), key=lambda x: x[1], reverse=True))\n",
    "mapping = {key: i for i, key in enumerate(d_sorted.keys())}\n",
    "\n",
    "import json\n",
    "with open('../data/pseudo/preprocess/others/condon_mapping.json', 'w') as output:\n",
    "    json.dump(mapping, output, indent='\\t')\n",
    "\n",
    "import json\n",
    "with open('../data/pseudo/preprocess/others/condon_mapping.json', 'r') as input_:\n",
    "    mapping = json.load(input_)\n",
    "\n",
    "# 22*2 seconds\n",
    "%time o_c_ = o_c.applymap(lambda x: mapping[x])\n",
    "%time i_c_ = i_c.applymap(lambda x: mapping[x])\n",
    "np.save('../data/pseudo/preprocess/o_c_-_-.npy', o_c_.to_numpy()[mask])\n",
    "np.save('../data/pseudo/preprocess/i_c_-_-.npy', i_c_.to_numpy()[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c_ = np.load('../data/pseudo/preprocess/o_c_-_-.npy')\n",
    "i_c_ = np.load('../data/pseudo/preprocess/i_c_-_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove based on SNP counts\n",
    "similar to variance threshold but seems better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2*2 minutes\n",
    "%time variant_counts_o = o_c.apply(pd.Series.value_counts, axis=0)\n",
    "%time variant_counts_i = i_c.apply(pd.Series.value_counts, axis=0)\n",
    "np.save('../data/pseudo/preprocess/others/variant_counts_o.npy', variant_counts_o)\n",
    "np.save('../data/pseudo/preprocess/others/variant_counts_i.npy', variant_counts_i)\n",
    "\n",
    "variant_counts_o = pd.DataFrame(np.load('../data/pseudo/preprocess/others/variant_counts_o.npy'))\n",
    "variant_counts_i = pd.DataFrame(np.load('../data/pseudo/preprocess/others/variant_counts_i.npy'))\n",
    "\n",
    "# True     85753\n",
    "variant_max_counts_o = variant_counts_o.max()\n",
    "# True      56191\n",
    "variant_max_counts_i = variant_counts_i.max()\n",
    "\n",
    "o_c_v = o_c_[mask][:, variant_max_counts_o<121]\n",
    "i_c_v = i_c_[mask][:, variant_max_counts_i<121]\n",
    "np.save('../data/pseudo/preprocess/o_c_v_-.npy', o_c_v)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_-.npy', i_c_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^2$ on the previous result\n",
    "because some features are all 0's, so gives `divide by 0` warning\n",
    "\n",
    "no warning if we remove those features (on the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "o_c_x = SelectKBest(chi2, k=85753//2).fit_transform(o_c_v, records['toby'][mask].astype('i4'))\n",
    "i_c_x = SelectKBest(chi2, k=56191//2).fit_transform(i_c_v, records['toby'][mask].astype('i4'))\n",
    "\n",
    "np.save('../data/pseudo/preprocess/o_c_x_-.npy', o_c_x)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_-.npy', i_c_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c_v = np.load('../data/pseudo/preprocess/o_c_v_-.npy')\n",
    "i_c_v = np.load('../data/pseudo/preprocess/i_c_v_-.npy')\n",
    "o_c_x = np.load('../data/pseudo/preprocess/o_c_x_-.npy')\n",
    "i_c_x = np.load('../data/pseudo/preprocess/i_c_x_-.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes very long but about one night\n",
    "from strkernel.mismatch_kernel import MismatchKernel\n",
    "\n",
    "%time o_c__s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_)\n",
    "%time i_c__s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_)\n",
    "np.save('../data/pseudo/preprocess/o_c_-_s.npy', o_c__s.kernel)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_s.npy', i_c__s.kernel)\n",
    "\n",
    "%time o_c_v_s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_v)\n",
    "%time i_c_v_s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_v)\n",
    "np.save('../data/pseudo/preprocess/o_c_v_s.npy', o_c_v_s.kernel)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_s.npy', i_c_v_s.kernel)\n",
    "\n",
    "%time o_c_x_s = MismatchKernel(l=125, k=2, m=1).get_kernel(o_c_x)\n",
    "%time i_c_x_s = MismatchKernel(l=125, k=2, m=1).get_kernel(i_c_x)\n",
    "np.save('../data/pseudo/preprocess/o_c_x_s.npy', o_c_x_s.kernel)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_s.npy', i_c_x_s.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 31s, sys: 14.6 s, total: 3min 46s\n",
      "Wall time: 10 s\n",
      "CPU times: user 2min 17s, sys: 5.81 s, total: 2min 23s\n",
      "Wall time: 4.67 s\n",
      "CPU times: user 56.3 s, sys: 2.24 s, total: 58.5 s\n",
      "Wall time: 1.7 s\n",
      "CPU times: user 41 s, sys: 1.68 s, total: 42.7 s\n",
      "Wall time: 1.22 s\n",
      "CPU times: user 29.2 s, sys: 1.24 s, total: 30.5 s\n",
      "Wall time: 867 ms\n",
      "CPU times: user 22.1 s, sys: 931 ms, total: 23 s\n",
      "Wall time: 655 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%time o_c__p = PCA(n_components=119).fit_transform(o_c_)\n",
    "%time i_c__p = PCA(n_components=119).fit_transform(i_c_)\n",
    "np.save('../data/pseudo/preprocess/o_c_-_p.npy', o_c__p)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_p.npy', i_c__p)\n",
    "\n",
    "%time o_c_v_p = PCA(n_components=119).fit_transform(o_c_v)\n",
    "%time i_c_v_p = PCA(n_components=119).fit_transform(i_c_v)\n",
    "np.save('../data/pseudo/preprocess/o_c_v_p.npy', o_c_v_p)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_p.npy', i_c_v_p)\n",
    "\n",
    "%time o_c_x_p = PCA(n_components=119).fit_transform(o_c_x)\n",
    "%time i_c_x_p = PCA(n_components=119).fit_transform(i_c_x)\n",
    "np.save('../data/pseudo/preprocess/o_c_x_p.npy', o_c_x_p)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_p.npy', i_c_x_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.9 s, sys: 1.5 s, total: 35.4 s\n",
      "Wall time: 3.57 s\n",
      "CPU times: user 36.6 s, sys: 1.93 s, total: 38.5 s\n",
      "Wall time: 3.41 s\n",
      "CPU times: user 40.2 s, sys: 1.47 s, total: 41.7 s\n",
      "Wall time: 3.21 s\n",
      "CPU times: user 31.2 s, sys: 1.12 s, total: 32.3 s\n",
      "Wall time: 3.05 s\n",
      "CPU times: user 20.9 s, sys: 730 ms, total: 21.6 s\n",
      "Wall time: 2.69 s\n",
      "CPU times: user 14.6 s, sys: 479 ms, total: 15.1 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%time o_c__t = TSNE(n_components=3).fit_transform(o_c_)\n",
    "%time i_c__t = TSNE(n_components=3).fit_transform(i_c_)\n",
    "np.save('../data/pseudo/preprocess/o_c_-_t.npy', o_c__t)\n",
    "np.save('../data/pseudo/preprocess/i_c_-_t.npy', i_c__t)\n",
    "\n",
    "%time o_c_v_t = TSNE(n_components=3).fit_transform(o_c_v)\n",
    "%time i_c_v_t = TSNE(n_components=3).fit_transform(i_c_v)\n",
    "np.save('../data/pseudo/preprocess/o_c_v_t.npy', o_c_v_t)\n",
    "np.save('../data/pseudo/preprocess/i_c_v_t.npy', i_c_v_t)\n",
    "\n",
    "%time o_c_x_t = TSNE(n_components=3).fit_transform(o_c_x)\n",
    "%time i_c_x_t = TSNE(n_components=3).fit_transform(i_c_x)\n",
    "np.save('../data/pseudo/preprocess/o_c_x_t.npy', o_c_x_t)\n",
    "np.save('../data/pseudo/preprocess/i_c_x_t.npy', i_c_x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify all possible combinations are created\n",
    "import os\n",
    "d = os.listdir('../data/pseudo/preprocess/')\n",
    "s = {'{}_{}_{}_{}.npy'.format(impute, c_or_n, selection, extraction) for impute in 'io' for c_or_n in 'nc' for selection in '-vx' for extraction in '-pts'}\n",
    "s - set(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "s = {'{}_c_{}_{}.npy'.format(impute, selection, extraction)\n",
    "     for impute in 'io'\n",
    "     for selection in '-vx'\n",
    "     for extraction in '-pts'}\n",
    "\n",
    "data = {d: np.load(os.path.join('../data/pseudo/preprocess', d)) for d in s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "for file, X in data.items():\n",
    "    encoder = OneHotEncoder(categories='auto', sparse=False, dtype=np.int32)\n",
    "    X_encode = encoder.fit_transform(X)\n",
    "    np.save(os.path.join('../data/pseudo/preprocess/onehot', file), X_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
